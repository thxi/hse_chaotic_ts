{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lorenz-trajectory\" data-toc-modified-id=\"Lorenz-trajectory-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Lorenz trajectory</a></span><ul class=\"toc-item\"><li><span><a href=\"#CV-predictions\" data-toc-modified-id=\"CV-predictions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>CV predictions</a></span></li><li><span><a href=\"#compare-NP-sets\" data-toc-modified-id=\"compare-NP-sets-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>compare NP sets</a></span></li><li><span><a href=\"#Check-gpu\" data-toc-modified-id=\"Check-gpu-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Check gpu</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cluster\" data-toc-modified-id=\"Cluster-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Cluster</a></span></li><li><span><a href=\"#Quantile\" data-toc-modified-id=\"Quantile-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Quantile</a></span></li><li><span><a href=\"#heal\" data-toc-modified-id=\"heal-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>heal</a></span></li><li><span><a href=\"#Heal-test\" data-toc-modified-id=\"Heal-test-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Heal test</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:18:09.613340Z",
     "start_time": "2021-07-21T14:18:08.824730Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:18:11.856715Z",
     "start_time": "2021-07-21T14:18:09.617674Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.Lorentz import Lorentz\n",
    "from src.TSProcessor_GPU import TSProcessor\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:18:12.227059Z",
     "start_time": "2021-07-21T14:18:11.869791Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import normalize, denormalize, gen_sin_wave, plot_trajectories, plot_runs\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:18:12.254698Z",
     "start_time": "2021-07-21T14:18:12.243251Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:24:31.162985Z",
     "start_time": "2021-07-21T14:24:31.146950Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = 1900\n",
    "h_max = 100 # max prediction horizon (t+h)\n",
    "n_folds = 500\n",
    "\n",
    "\n",
    "points_in_template = 4\n",
    "max_template_spread = 10 # max distance between y_t1 and y_t2, y_1 and y_11\n",
    "\n",
    "\n",
    "# trajectories prediction parameters\n",
    "eps = 0.01\n",
    "n_trajectories = 24\n",
    "noise_amp = 0.01\n",
    "priori_eps = 0.2\n",
    "\n",
    "\n",
    "# unified prediction parameters\n",
    "dbs_eps = 0.01\n",
    "dbs_min_samples = int(0.25*n_trajectories)\n",
    "dbs_min_trajectories = int(0.25*n_trajectories)\n",
    "# dbs_cluster_difference = int(0.25*n_trajectories)\n",
    "\n",
    "alpha = 0.2\n",
    "max_err = 0.05\n",
    "min_trajectories = int(0.5*n_trajectories)\n",
    "\n",
    "assert n_trajectories*(1-2*alpha) > min_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:24:35.599297Z",
     "start_time": "2021-07-21T14:24:32.720839Z"
    }
   },
   "outputs": [],
   "source": [
    "x, _, _ = Lorentz().generate(0.1, 3000+n_folds*(train_size+h_max)-1) # -1 because of an implementation bug\n",
    "x, x_min, x_max = normalize(x[3000:]) # \"For the Lorenz series, the first 3000 observations are discarded...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:06:38.633905Z",
     "start_time": "2021-07-19T18:06:38.615688Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = {\n",
    "    'single': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'priori': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified_quantile': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified_healing': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified_template_healing': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:24:38.549348Z",
     "start_time": "2021-07-21T14:24:38.523602Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = pickle.load( open( \"runs.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:24:46.107548Z",
     "start_time": "2021-07-21T14:24:46.087691Z"
    }
   },
   "outputs": [],
   "source": [
    "# runs['unified_template_healing'] = {\n",
    "#         'rmse': np.zeros((n_folds, h_max)),\n",
    "#         'non_pred': np.zeros((n_folds, h_max)),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T23:20:02.420927Z",
     "start_time": "2021-07-14T21:34:34.666664Z"
    }
   },
   "outputs": [],
   "source": [
    "# priori and single\n",
    "for fold in tqdm(range(n_folds)):\n",
    "    t = (train_size+h_max) * fold\n",
    "    X_train = x[t:t+train_size].copy()\n",
    "    X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "    \n",
    "    start_points = max_template_spread * (points_in_template-1)\n",
    "    \n",
    "    X_start = x[t+train_size-start_points:t+train_size].copy()\n",
    "    X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "    \n",
    "    X_test_cpu = x[t+train_size:t+train_size+h_max].copy()\n",
    "    X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "    \n",
    "    \n",
    "    tsp = TSProcessor(\n",
    "        points_in_template=points_in_template,\n",
    "        max_template_spread=max_template_spread,\n",
    "        X_train=X_train,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # priori\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "        use_priori=True,\n",
    "        X_test=X_test,\n",
    "        priori_eps=priori_eps,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    \n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        use_priori=True,\n",
    "        X_test=X_test_cpu,\n",
    "        priori_eps=priori_eps,\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['priori']['rmse'][fold] = rmse\n",
    "    runs['priori']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # single\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=1,\n",
    "        noise_amp=0,\n",
    "        use_priori=False,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    X_pred = X_traj_pred[:, 0]\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['single']['rmse'][fold] = rmse\n",
    "    runs['single']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T01:02:11.774761Z",
     "start_time": "2021-07-14T23:20:02.648792Z"
    }
   },
   "outputs": [],
   "source": [
    "# unified and unified_quantile\n",
    "for fold in tqdm(range(n_folds)):\n",
    "    t = (train_size+h_max) * fold\n",
    "    X_train = x[t:t+train_size]\n",
    "    X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "    \n",
    "    start_points = max_template_spread * (points_in_template-1)\n",
    "    \n",
    "    X_start = x[t+train_size-start_points:t+train_size]\n",
    "    X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "    \n",
    "    X_test_cpu = x[t+train_size:t+train_size+h_max]\n",
    "    X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "    \n",
    "    \n",
    "    tsp = TSProcessor(\n",
    "        points_in_template=points_in_template,\n",
    "        max_template_spread=max_template_spread,\n",
    "        X_train=X_train,\n",
    "    )\n",
    "    \n",
    "    # unified\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    \n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['unified']['rmse'][fold] = rmse\n",
    "    runs['unified']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # unified_quantile\n",
    "    \n",
    "    # reusing X_traj_pred from previoius step\n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='quantile',\n",
    "        alpha=alpha,\n",
    "        max_err=max_err,\n",
    "        min_trajectories=min_trajectories,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['unified_quantile']['rmse'][fold] = rmse\n",
    "    runs['unified_quantile']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T04:21:14.893283Z",
     "start_time": "2021-07-15T01:02:11.994171Z"
    }
   },
   "outputs": [],
   "source": [
    "# healing\n",
    "for fold in tqdm(range(n_folds)):\n",
    "    t = (train_size+h_max) * fold\n",
    "    X_train = x[t:t+train_size]\n",
    "    X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "    \n",
    "    start_points = max_template_spread * (points_in_template-1)\n",
    "    \n",
    "    X_start = x[t+train_size-start_points:t+train_size]\n",
    "    X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "    \n",
    "    X_test_cpu = x[t+train_size:t+train_size+h_max]\n",
    "    X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "    \n",
    "    \n",
    "    tsp = TSProcessor(\n",
    "        points_in_template=points_in_template,\n",
    "        max_template_spread=max_template_spread,\n",
    "        X_train=X_train,\n",
    "    )\n",
    "    \n",
    "    # healing\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "        X_pred=X_pred,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "        X_pred=X_pred,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['unified_healing']['rmse'][fold] = rmse\n",
    "    runs['unified_healing']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:28:00.590872Z",
     "start_time": "2021-07-21T14:25:12.658970Z"
    }
   },
   "outputs": [],
   "source": [
    "# template healing\n",
    "for fold in tqdm(range(n_folds)):\n",
    "    t = (train_size+h_max) * fold\n",
    "    X_train = x[t:t+train_size]\n",
    "    X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "    \n",
    "    start_points = max_template_spread * (points_in_template-1)\n",
    "    \n",
    "    X_start = x[t+train_size-start_points:t+train_size]\n",
    "    X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "    \n",
    "    X_test_cpu = x[t+train_size:t+train_size+h_max]\n",
    "    X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "    \n",
    "    \n",
    "    tsp = TSProcessor(\n",
    "        points_in_template=points_in_template,\n",
    "        max_template_spread=max_template_spread,\n",
    "        X_train=X_train,\n",
    "    )\n",
    "    \n",
    "    # unified\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    \n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    X_pred = torch.from_numpy(X_pred).to('cuda')\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    X_traj_pred = tsp.heal(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "        X_pred=X_pred,\n",
    "        random_seed=1\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['unified_template_healing']['rmse'][fold] = rmse\n",
    "    runs['unified_template_healing']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:11:32.167445Z",
     "start_time": "2021-07-19T20:11:32.152273Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle.dump(runs, open( \"runs.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:11:06.812031Z",
     "start_time": "2021-07-19T20:11:06.798205Z"
    }
   },
   "outputs": [],
   "source": [
    "runs_processed = deepcopy(runs)\n",
    "for method in runs_processed.keys():\n",
    "    rmses = runs_processed[method]['rmse']\n",
    "    non_preds = runs_processed[method]['non_pred']\n",
    "    non_preds = 100*non_preds.sum(axis=0) / non_preds.shape[0]\n",
    "    # might be bogged\n",
    "    # np.sqrt(np.nan_to_num(rmses / (rmses.shape[0] - np.isnan(rmses).sum(axis=0))).sum(axis=0))\n",
    "    rmses = np.sqrt(np.nanmean(rmses, axis=0))\n",
    "    runs_processed[method]['rmse'] = rmses\n",
    "    runs_processed[method]['non_pred'] = non_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:11:07.437531Z",
     "start_time": "2021-07-19T20:11:07.038310Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_runs(runs_processed, h_max, filename=f'images/fig4_healing_{h_max}_{noise_amp:.3f}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:12:23.742524Z",
     "start_time": "2021-07-19T20:12:23.727069Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for method in runs.keys():\n",
    "    rmse = runs[method]['rmse']\n",
    "    rmses = np.sqrt(np.nanmean(rmse, axis=0))\n",
    "    tmp += [(method, i+1, rmses[i]) for i in range(len(rmses))]\n",
    "\n",
    "runs_df = pd.DataFrame(tmp, columns=['method', 'step', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:12:23.956786Z",
     "start_time": "2021-07-19T20:12:23.943941Z"
    }
   },
   "outputs": [],
   "source": [
    "runs_df.to_csv('runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:12:24.158228Z",
     "start_time": "2021-07-19T20:12:24.145950Z"
    }
   },
   "outputs": [],
   "source": [
    "diff = (runs_df[runs_df['method'] == 'unified_healing']['rmse'].to_numpy() -\n",
    " runs_df[runs_df['method'] == 'unified']['rmse'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:12:24.591020Z",
     "start_time": "2021-07-19T20:12:24.346729Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.title('Difference healing')\n",
    "plt.bar(range(1, len(diff)+1), diff)\n",
    "plt.xlabel('Forecasting horizon');\n",
    "plt.ylabel('RMSE difference');\n",
    "plt.ylim(-0.15, 0.15)\n",
    "\n",
    "fig.savefig('images/healing_improvement.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:12:24.793403Z",
     "start_time": "2021-07-19T20:12:24.780990Z"
    }
   },
   "outputs": [],
   "source": [
    "diff = (runs_df[runs_df['method'] == 'unified_healing']['rmse'].to_numpy() -\n",
    " runs_df[runs_df['method'] == 'unified_template_healing']['rmse'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T20:12:25.225980Z",
     "start_time": "2021-07-19T20:12:24.982807Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.title('Difference healing')\n",
    "plt.bar(range(1, len(diff)+1), diff)\n",
    "plt.xlabel('Forecasting horizon');\n",
    "plt.ylabel('RMSE difference');\n",
    "plt.ylim(-0.15, 0.15)\n",
    "\n",
    "fig.savefig('images/healing_improvement_template.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare NP sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:22:18.161494Z",
     "start_time": "2021-07-21T14:22:18.144385Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = 1900\n",
    "h_max = 100 # max prediction horizon (t+h)\n",
    "n_folds = 100\n",
    "\n",
    "\n",
    "points_in_template = 4\n",
    "max_template_spread = 10 # max distance between y_t1 and y_t2, y_1 and y_11\n",
    "\n",
    "\n",
    "# trajectories prediction parameters\n",
    "eps = 0.01\n",
    "n_trajectories = 24\n",
    "noise_amp = 0.01\n",
    "priori_eps = 0.2\n",
    "\n",
    "\n",
    "# unified prediction parameters\n",
    "dbs_eps = 0.01\n",
    "dbs_min_samples = int(0.25*n_trajectories)\n",
    "dbs_min_trajectories = int(0.25*n_trajectories)\n",
    "# dbs_cluster_difference = int(0.25*n_trajectories)\n",
    "\n",
    "alpha = 0.2\n",
    "max_err = 0.05\n",
    "min_trajectories = int(0.5*n_trajectories)\n",
    "\n",
    "assert n_trajectories*(1-2*alpha) > min_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-21T14:22:19.270890Z",
     "start_time": "2021-07-21T14:22:18.665464Z"
    }
   },
   "outputs": [],
   "source": [
    "x, _, _ = Lorentz().generate(0.1, 3000+n_folds*(train_size+h_max)-1) # -1 because of an implementation bug\n",
    "x, x_min, x_max = normalize(x[3000:]) # \"For the Lorenz series, the first 3000 observations are discarded...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:06:38.633905Z",
     "start_time": "2021-07-19T18:06:38.615688Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = {\n",
    "    'single': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'priori': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified_quantile': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified_healing': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "    'unified_template_healing': {\n",
    "        'rmse': np.zeros((n_folds, h_max)),\n",
    "        'non_pred': np.zeros((n_folds, h_max)),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:06:39.369977Z",
     "start_time": "2021-07-19T18:06:39.350182Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = pickle.load( open( \"runs.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:06:41.060349Z",
     "start_time": "2021-07-19T18:06:41.047258Z"
    }
   },
   "outputs": [],
   "source": [
    "# runs['unified_template_healing'] = {\n",
    "#         'rmse': np.zeros((n_folds, h_max)),\n",
    "#         'non_pred': np.zeros((n_folds, h_max)),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T23:20:02.420927Z",
     "start_time": "2021-07-14T21:34:34.666664Z"
    }
   },
   "outputs": [],
   "source": [
    "# priori and single\n",
    "for fold in tqdm(range(n_folds)):\n",
    "    t = (train_size+h_max) * fold\n",
    "    X_train = x[t:t+train_size].copy()\n",
    "    X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "    \n",
    "    start_points = max_template_spread * (points_in_template-1)\n",
    "    \n",
    "    X_start = x[t+train_size-start_points:t+train_size].copy()\n",
    "    X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "    \n",
    "    X_test_cpu = x[t+train_size:t+train_size+h_max].copy()\n",
    "    X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "    \n",
    "    \n",
    "    tsp = TSProcessor(\n",
    "        points_in_template=points_in_template,\n",
    "        max_template_spread=max_template_spread,\n",
    "        X_train=X_train,\n",
    "    )\n",
    "    \n",
    "\n",
    "    # priori\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=n_trajectories,\n",
    "        noise_amp=noise_amp,\n",
    "        use_priori=True,\n",
    "        X_test=X_test,\n",
    "        priori_eps=priori_eps,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    \n",
    "    unified_result = tsp.predict_unified(\n",
    "        X_traj_pred,\n",
    "        method='cluster',\n",
    "        use_priori=True,\n",
    "        X_test=X_test_cpu,\n",
    "        priori_eps=priori_eps,\n",
    "        dbs_min_trajectories=dbs_min_trajectories,\n",
    "        dbs_eps=dbs_eps,\n",
    "        dbs_min_samples=dbs_min_samples,\n",
    "    )\n",
    "    X_pred = unified_result['X_pred']\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['priori']['rmse'][fold] = rmse\n",
    "    runs['priori']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # single\n",
    "    X_traj_pred = tsp.predict_trajectories(\n",
    "        X_start, h_max,\n",
    "        eps=eps,\n",
    "        n_trajectories=1,\n",
    "        noise_amp=0,\n",
    "        use_priori=False,\n",
    "    )\n",
    "    X_traj_pred = X_traj_pred.cpu().numpy()\n",
    "    X_pred = X_traj_pred[:, 0]\n",
    "    \n",
    "    non_pred = np.isnan(X_pred).astype(int)\n",
    "    rmse = (X_pred - X_test_cpu)**2\n",
    "    runs['single']['rmse'][fold] = rmse\n",
    "    runs['single']['non_pred'][fold] = non_pred\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T15:33:29.053637Z",
     "start_time": "2021-07-14T15:33:29.039164Z"
    }
   },
   "source": [
    "### Check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:14:53.090201Z",
     "start_time": "2021-07-19T17:14:53.073440Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "h_max = 100 # max prediction horizon (t+h)\n",
    "n_folds = 500\n",
    "\n",
    "\n",
    "points_in_template = 4\n",
    "max_template_spread = 10 # max distance between y_t1 and y_t2, y_1 and y_11\n",
    "\n",
    "\n",
    "# trajectories prediction parameters\n",
    "eps = 0.01\n",
    "n_trajectories = 24\n",
    "noise_amp = 0.01\n",
    "priori_eps = 0.2\n",
    "\n",
    "\n",
    "# unified prediction parameters\n",
    "dbs_eps = 0.01\n",
    "dbs_min_samples = int(0.25*n_trajectories)\n",
    "dbs_min_trajectories = int(0.25*n_trajectories)\n",
    "# dbs_cluster_difference = int(0.25*n_trajectories)\n",
    "\n",
    "alpha = 0.2\n",
    "max_err = 0.05\n",
    "min_trajectories = int(0.5*n_trajectories)\n",
    "\n",
    "assert n_trajectories*(1-2*alpha) > min_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:14:54.792083Z",
     "start_time": "2021-07-19T17:14:53.165790Z"
    }
   },
   "outputs": [],
   "source": [
    "x, _, _ = Lorentz().generate(0.1, 3000+n_folds*(train_size+h_max)-1) # -1 because of an implementation bug\n",
    "x, x_min, x_max = normalize(x[3000:]) # \"For the Lorenz series, the first 3000 observations are discarded...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:00:31.570975Z",
     "start_time": "2021-07-19T17:00:31.431444Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "t = (train_size+h_max) * fold\n",
    "\n",
    "X_train = x[t:t+train_size]\n",
    "X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "\n",
    "start_points = max_template_spread * (points_in_template-1)\n",
    "\n",
    "X_start = x[t+train_size-start_points:t+train_size]\n",
    "X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "\n",
    "X_test_cpu = x[t+train_size:t+train_size+h_max]\n",
    "X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "\n",
    "\n",
    "tsp = TSProcessor(\n",
    "    points_in_template=points_in_template,\n",
    "    max_template_spread=max_template_spread,\n",
    "    X_train=X_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:00:36.589827Z",
     "start_time": "2021-07-19T17:00:31.605787Z"
    }
   },
   "outputs": [],
   "source": [
    "X_traj_pred = tsp.predict_trajectories(\n",
    "    X_start, h_max,\n",
    "    eps=eps,\n",
    "    n_trajectories=n_trajectories,\n",
    "    noise_amp=noise_amp,\n",
    "    use_priori=False,\n",
    "    X_test=X_test,\n",
    "    priori_eps=priori_eps,\n",
    "    random_seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:00:37.866941Z",
     "start_time": "2021-07-19T17:00:37.848829Z"
    }
   },
   "outputs": [],
   "source": [
    "X_traj_pred = X_traj_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:00:38.295904Z",
     "start_time": "2021-07-19T17:00:38.173775Z"
    }
   },
   "outputs": [],
   "source": [
    "unified_result = tsp.predict_unified(\n",
    "    X_traj_pred,\n",
    "    method='cluster',\n",
    "    dbs_min_trajectories=dbs_min_trajectories,\n",
    "    dbs_eps=dbs_eps,\n",
    "    dbs_min_samples=dbs_min_samples,\n",
    ")\n",
    "X_pred = unified_result['X_pred']\n",
    "\n",
    "non_pred = np.isnan(X_pred).astype(int)\n",
    "rmse = (X_pred - X_test_cpu)**2\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:00:45.125842Z",
     "start_time": "2021-07-19T17:00:44.837144Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trajectories(\n",
    "    'Lorenz', X_train.cpu().numpy(), X_test.cpu().numpy(), # plotting since X_start\n",
    "    noise_amp, n_trajectories,\n",
    "    X_traj_pred, X_pred#, filename=f'Lorenz_cluster_{fold}_{noise_amp:.2f}.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T09:35:21.391295Z",
     "start_time": "2021-07-19T09:35:21.185892Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unified_result = tsp.predict_unified(\n",
    "    X_traj_pred,\n",
    "    method='quantile',\n",
    "    use_priori=False,\n",
    "    min_trajectories=min_trajectories,\n",
    "    max_err=max_err,\n",
    "    alpha=alpha,\n",
    ")\n",
    "X_pred = unified_result['X_pred']\n",
    "qs = unified_result['qs']\n",
    "traj_alive = unified_result['traj_alive']\n",
    "\n",
    "non_pred = np.isnan(X_pred).astype(int)\n",
    "rmse = (X_pred - X_test_cpu)**2\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T08:42:21.482307Z",
     "start_time": "2021-07-19T08:42:21.072204Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trajectories(\n",
    "    'Lorenz', X_train.cpu().numpy(), X_test.cpu().numpy(), # plotting since X_start\n",
    "    noise_amp, n_trajectories,\n",
    "    X_traj_pred, X_pred, non_pred, rmse#, filename=f'Lorenz_cluster_{fold}_{noise_amp:.2f}.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T08:42:23.777162Z",
     "start_time": "2021-07-19T08:42:23.409043Z"
    }
   },
   "outputs": [],
   "source": [
    "# quantile plot\n",
    "\n",
    "fig = plt.figure(figsize=[14, 8])\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(X_test_cpu, label='123', zorder=1)\n",
    "\n",
    "plt.ylim(-0.1, 1.1)\n",
    "\n",
    "for i in range(n_trajectories):\n",
    "    plt.plot(X_traj_pred[:, i], c='orange', lw=0.5, zorder=0)\n",
    "\n",
    "plt.scatter(range(X_pred.size),\n",
    "            X_pred,\n",
    "            label='predicted',\n",
    "            c='red',\n",
    "            zorder=2)\n",
    "\n",
    "plt.fill_between(range(len(qs)), qs[:, 0], qs[:, 1], alpha=0.3)\n",
    "\n",
    "plt.title('Predicted trajectories (orange)')\n",
    "plt.legend(loc='upper right');\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(range(len(traj_alive)), traj_alive)\n",
    "plt.hlines(y=min_trajectories, xmin=0, xmax=len(traj_alive),\n",
    "           color='orange', label='min_trajectories')\n",
    "plt.legend()\n",
    "plt.ylim(0, n_trajectories);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:33:59.551526Z",
     "start_time": "2021-07-19T17:33:59.395515Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = 0\n",
    "t = (train_size+h_max) * fold\n",
    "\n",
    "X_train = x[t:t+train_size]\n",
    "X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "\n",
    "start_points = max_template_spread * (points_in_template-1)\n",
    "\n",
    "X_start = x[t+train_size-start_points:t+train_size]\n",
    "X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "\n",
    "X_test_cpu = x[t+train_size:t+train_size+h_max]\n",
    "X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "\n",
    "\n",
    "tsp = TSProcessor(\n",
    "    points_in_template=points_in_template,\n",
    "    max_template_spread=max_template_spread,\n",
    "    X_train=X_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:04.731562Z",
     "start_time": "2021-07-19T17:33:59.748525Z"
    }
   },
   "outputs": [],
   "source": [
    "X_traj_pred = tsp.predict_trajectories(\n",
    "    X_start, h_max,\n",
    "    eps=eps,\n",
    "    n_trajectories=n_trajectories,\n",
    "    noise_amp=noise_amp,\n",
    "    use_priori=False,\n",
    "    X_test=X_test,\n",
    "    priori_eps=priori_eps,\n",
    "    random_seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:04.777654Z",
     "start_time": "2021-07-19T17:34:04.766077Z"
    }
   },
   "outputs": [],
   "source": [
    "X_traj_pred = X_traj_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:04.917586Z",
     "start_time": "2021-07-19T17:34:04.806985Z"
    }
   },
   "outputs": [],
   "source": [
    "unified_result = tsp.predict_unified(\n",
    "    X_traj_pred,\n",
    "    method='cluster',\n",
    "    dbs_min_trajectories=dbs_min_trajectories,\n",
    "    dbs_eps=dbs_eps,\n",
    "    dbs_min_samples=dbs_min_samples,\n",
    ")\n",
    "X_pred = unified_result['X_pred']\n",
    "\n",
    "non_pred = np.isnan(X_pred).astype(int)\n",
    "rmse = (X_pred - X_test_cpu)**2\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:05.232756Z",
     "start_time": "2021-07-19T17:34:04.946695Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trajectories(\n",
    "    'Lorenz', X_train.cpu().numpy(), X_test.cpu().numpy(), # plotting since X_start\n",
    "    noise_amp, n_trajectories,\n",
    "    X_traj_pred, X_pred#, filename=f'Lorenz_cluster_{fold}_{noise_amp:.2f}.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:05.274698Z",
     "start_time": "2021-07-19T17:34:05.262737Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pred = torch.from_numpy(X_pred).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:05.316194Z",
     "start_time": "2021-07-19T17:34:05.304080Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test[88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:34.266145Z",
     "start_time": "2021-07-19T17:34:05.345238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_traj_pred = tsp.heal(\n",
    "    X_start, h_max,\n",
    "    eps=eps,\n",
    "    n_trajectories=n_trajectories,\n",
    "    noise_amp=noise_amp,\n",
    "    X_pred=X_pred,\n",
    "    random_seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:34.348597Z",
     "start_time": "2021-07-19T17:34:34.297190Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:34.391028Z",
     "start_time": "2021-07-19T17:34:34.379372Z"
    }
   },
   "outputs": [],
   "source": [
    "X_traj_pred = X_traj_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:34.527009Z",
     "start_time": "2021-07-19T17:34:34.421371Z"
    }
   },
   "outputs": [],
   "source": [
    "unified_result = tsp.predict_unified(\n",
    "    X_traj_pred,\n",
    "    method='cluster',\n",
    "    dbs_min_trajectories=dbs_min_trajectories,\n",
    "    dbs_eps=dbs_eps,\n",
    "    dbs_min_samples=dbs_min_samples,\n",
    ")\n",
    "X_pred = unified_result['X_pred']\n",
    "\n",
    "non_pred = np.isnan(X_pred).astype(int)\n",
    "rmse = (X_pred - X_test_cpu)**2\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:34:34.860223Z",
     "start_time": "2021-07-19T17:34:34.556325Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trajectories(\n",
    "    'Lorenz', X_train.cpu().numpy(), X_test.cpu().numpy(), # plotting since X_start\n",
    "    noise_amp, n_trajectories,\n",
    "    X_traj_pred, X_pred#, filename=f'Lorenz_cluster_{fold}_{noise_amp:.2f}.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:12:00.026146Z",
     "start_time": "2021-07-19T17:12:00.006002Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = 50\n",
    "h_max = 20 # max prediction horizon (t+h)\n",
    "n_folds = 500\n",
    "\n",
    "\n",
    "points_in_template = 3\n",
    "max_template_spread = 2 # max distance between y_t1 and y_t2, y_1 and y_11\n",
    "\n",
    "\n",
    "# trajectories prediction parameters\n",
    "eps = 0.01\n",
    "n_trajectories = 24\n",
    "noise_amp = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:12:00.280614Z",
     "start_time": "2021-07-19T17:12:00.233170Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.concatenate([\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "    np.array(range(20)),\n",
    "    np.array(range(18, 0, -1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:12:00.357735Z",
     "start_time": "2021-07-19T17:12:00.344001Z"
    }
   },
   "outputs": [],
   "source": [
    "t=0\n",
    "X_train = x[t:t+train_size]\n",
    "X_train = torch.from_numpy(X_train).type(torch.float32).to('cuda')\n",
    "\n",
    "start_points = max_template_spread * (points_in_template-1)\n",
    "\n",
    "X_start = x[t+train_size-start_points:t+train_size]\n",
    "X_start = torch.from_numpy(X_start).type(torch.float32).to('cuda')\n",
    "\n",
    "X_test_cpu = x[t+train_size:t+train_size+h_max]\n",
    "X_test = torch.from_numpy(X_test_cpu).type(torch.float32).to('cuda')\n",
    "\n",
    "tsp = TSProcessor(\n",
    "    points_in_template=points_in_template,\n",
    "    max_template_spread=max_template_spread,\n",
    "    X_train=X_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:12:00.975263Z",
     "start_time": "2021-07-19T17:12:00.954807Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pred = X_test.clone()\n",
    "X_pred[0] = np.nan\n",
    "X_pred[6] = np.nan\n",
    "X_pred[10] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:12:11.003454Z",
     "start_time": "2021-07-19T17:12:10.983406Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:12:11.606207Z",
     "start_time": "2021-07-19T17:12:11.210269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_traj_pred = tsp.heal(\n",
    "    X_start, h_max,\n",
    "    eps=eps,\n",
    "    n_trajectories=n_trajectories,\n",
    "    noise_amp=noise_amp,\n",
    "    X_pred=X_pred,\n",
    "    random_seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:13:12.837229Z",
     "start_time": "2021-07-19T17:13:12.818140Z"
    }
   },
   "outputs": [],
   "source": [
    "X_traj_pred = X_traj_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:13:13.192314Z",
     "start_time": "2021-07-19T17:13:13.096916Z"
    }
   },
   "outputs": [],
   "source": [
    "unified_result = tsp.predict_unified(\n",
    "    X_traj_pred,\n",
    "    method='cluster',\n",
    "    dbs_min_trajectories=dbs_min_trajectories,\n",
    "    dbs_eps=dbs_eps,\n",
    "    dbs_min_samples=dbs_min_samples,\n",
    ")\n",
    "X_pred = unified_result['X_pred']\n",
    "\n",
    "non_pred = np.isnan(X_pred).astype(int)\n",
    "rmse = (X_pred - X_test_cpu)**2\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:13:23.147668Z",
     "start_time": "2021-07-19T17:13:22.862316Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_trajectories(\n",
    "    'random', X_train.cpu().numpy(), X_test.cpu().numpy(), # plotting since X_start\n",
    "    noise_amp, n_trajectories,\n",
    "    X_traj_pred, X_pred#, filename=f'Lorenz_cluster_{fold}_{noise_amp:.2f}.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traj_pred = tsp.heal(\n",
    "    X_start, h_max,\n",
    "    eps=eps,\n",
    "    n_trajectories=n_trajectories,\n",
    "    noise_amp=noise_amp,\n",
    "    X_pred=X_pred,\n",
    "    random_seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.85,
   "position": {
    "height": "790.85px",
    "left": "1538px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
